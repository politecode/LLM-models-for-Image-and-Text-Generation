{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOVIdtqVREu01UrY4ON09Us",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/politecode/LLM-models-for-Image-and-Text-Generation/blob/main/LLAMA_2_Chat%2BImage_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm_DdEqU1lt8",
        "outputId": "53c0115f-c7de-4771-d313-2aef1c2d3aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting replicate\n",
            "  Downloading replicate-0.22.0-py3-none-any.whl (35 kB)\n",
            "Collecting httpx<1,>=0.21.0 (from replicate)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.2)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (1.10.13)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.21.0->replicate)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.21.0->replicate)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.0)\n",
            "Installing collected packages: h11, httpcore, httpx, replicate\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 replicate-0.22.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! pip install replicate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "key = \"Paste your Api Key here\"\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = key"
      ],
      "metadata": {
        "id": "MsHjBeBz12D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "output = replicate.run(\n",
        "    \"stability-ai/stable-diffusion:db21e45d3f7023abc2a46ee38a23973f6dce16bb082a930b0c49861f96d1e5bf\",\n",
        "    input={\"text\": \"a beautifull nature Image\"}\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGIl07hY9ih2",
        "outputId": "60b794b5-54d0-4831-f61b-fe1768815c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://replicate.delivery/pbxt/qHamyc6yL972M9g70VcYTgIvfBGYlTq6AhBHC70ra1NiDXCJA/out-0.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "# Prompts\n",
        "pre_prompt = \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'.\"\n",
        "prompt_input = \"How I can Learn LLms. Give Roadmap?\"\n",
        "\n",
        "# Generate LLM response\n",
        "output = replicate.run('a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5', # LLM model\n",
        "                        input={\"prompt\": f\"{pre_prompt} {prompt_input} Assistant: \", # Prompts\n",
        "                        \"temperature\":0.6, \"top_p\":0.9, \"max_length\":508, \"repetition_penalty\":1})  # Model par"
      ],
      "metadata": {
        "id": "tEE1oZMo12Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4DgQC5C12R_",
        "outputId": "9bac8712-7d61-43ce-ce4f-4e86c4b7fd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Prediction.output_iterator at 0x7e3fbb309310>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_response = \"\"\n",
        "\n",
        "for item in output:\n",
        "  full_response += item\n",
        "\n",
        "print(full_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtMroBhd12bG",
        "outputId": "74b0e20e-d8bc-41f7-e89f-b27c6bf5e9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, I'd be happy to help! Learning LLMs can be a challenging but rewarding journey. Here's a roadmap to help you get started:\n",
            "1. Start with the basics: Before diving into LLMs, it's important to have a solid understanding of the basics of machine learning. This includes concepts like supervised and unsupervised learning, regression, classification, and clustering.\n",
            "2. Choose a programming language: LLMs are typically implemented using popular programming languages like Python, R, or Julia. Choose a language that you're comfortable with and has good support for machine learning libraries.\n",
            "3. Learn the fundamentals of LLMs: Once you have a good grasp of the basics, start learning about the fundamentals of LLMs. This includes understanding the different types of LLMs, such as feedforward networks, recurrent networks, and transformers.\n",
            "4. Practice with tutorials and projects: The best way to learn LLMs is by practicing with tutorials and projects. Start with simple projects and gradually work your way up to more complex ones.\n",
            "5. Read books and research papers: There are many great books and research papers on LLMs that can help you deepen your understanding of the subject. Some popular books include \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, and \"Neural Networks and Deep Learning\" by Michael A. Nielsen.\n",
            "6. Join online communities: There are many online communities, such as Kaggle, GitHub, and Reddit, where you can learn from other machine learning practitioners and get feedback on your projects.\n",
            "7. Take online courses: There are many online courses available that can help you learn LLMs, such as those offered by Coursera, edX, and Udemy.\n",
            "8. Work on projects: The best way to learn LLMs is by working on real-world projects. Start with simple projects and gradually work your way up to more complex ones.\n",
            "9. Read research papers: Keep up-to-date with the latest research in LLM\n"
          ]
        }
      ]
    }
  ]
}